{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "print(os.listdir(\"../input\"))\n",
    "# Setting seed for reproducability\n",
    "np.random.seed(1234)  \n",
    "PYTHONHASHSEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UnitNumber', 'Cycle', 'Op_Setting_1', 'Op_Setting_2', 'Op_Setting_3', 'Sensor_1', 'Sensor_2', 'Sensor_3', 'Sensor_4', 'Sensor_5', 'Sensor_6', 'Sensor_7', 'Sensor_8', 'Sensor_9', 'Sensor_10', 'Sensor_11', 'Sensor_12', 'Sensor_13', 'Sensor_14', 'Sensor_15', 'Sensor_16', 'Sensor_17', 'Sensor_18', 'Sensor_19', 'Sensor_20', 'Sensor_21']\n"
     ]
    }
   ],
   "source": [
    "target_var = ['Target_Remaining_Useful_Life']\n",
    "index_columns_names =  [\"UnitNumber\",\"Cycle\"]\n",
    "op_settings_columns = [\"Op_Setting_\"+str(i) for i in range(1,4)]\n",
    "sensor_columns =[\"Sensor_\"+str(i) for i in range(1,22)]\n",
    "column_names = index_columns_names + op_settings_columns + sensor_columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (20631, 28) test shape:  (13096, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitNumber</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>Op_Setting_1</th>\n",
       "      <th>Op_Setting_2</th>\n",
       "      <th>Op_Setting_3</th>\n",
       "      <th>Sensor_1</th>\n",
       "      <th>Sensor_2</th>\n",
       "      <th>Sensor_3</th>\n",
       "      <th>Sensor_4</th>\n",
       "      <th>Sensor_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor_12</th>\n",
       "      <th>Sensor_13</th>\n",
       "      <th>Sensor_14</th>\n",
       "      <th>Sensor_15</th>\n",
       "      <th>Sensor_16</th>\n",
       "      <th>Sensor_17</th>\n",
       "      <th>Sensor_18</th>\n",
       "      <th>Sensor_19</th>\n",
       "      <th>Sensor_20</th>\n",
       "      <th>Sensor_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.02</td>\n",
       "      <td>1585.29</td>\n",
       "      <td>1398.21</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.72</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8125.55</td>\n",
       "      <td>8.4052</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.86</td>\n",
       "      <td>23.3735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1588.45</td>\n",
       "      <td>1395.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.16</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8139.62</td>\n",
       "      <td>8.3803</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1586.94</td>\n",
       "      <td>1401.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.97</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8130.10</td>\n",
       "      <td>8.4441</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.08</td>\n",
       "      <td>23.4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1584.12</td>\n",
       "      <td>1406.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.38</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8132.90</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.51</td>\n",
       "      <td>1587.19</td>\n",
       "      <td>1401.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.15</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8129.54</td>\n",
       "      <td>8.4031</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UnitNumber  Cycle  Op_Setting_1  Op_Setting_2  Op_Setting_3  Sensor_1  \\\n",
       "0           1      1        0.0023        0.0003         100.0    518.67   \n",
       "1           1      2       -0.0027       -0.0003         100.0    518.67   \n",
       "2           1      3        0.0003        0.0001         100.0    518.67   \n",
       "3           1      4        0.0042        0.0000         100.0    518.67   \n",
       "4           1      5        0.0014        0.0000         100.0    518.67   \n",
       "\n",
       "   Sensor_2  Sensor_3  Sensor_4  Sensor_5    ...      Sensor_12  Sensor_13  \\\n",
       "0    643.02   1585.29   1398.21     14.62    ...         521.72    2388.03   \n",
       "1    641.71   1588.45   1395.42     14.62    ...         522.16    2388.06   \n",
       "2    642.46   1586.94   1401.34     14.62    ...         521.97    2388.03   \n",
       "3    642.44   1584.12   1406.42     14.62    ...         521.38    2388.05   \n",
       "4    642.51   1587.19   1401.92     14.62    ...         522.15    2388.03   \n",
       "\n",
       "   Sensor_14  Sensor_15  Sensor_16  Sensor_17  Sensor_18  Sensor_19  \\\n",
       "0    8125.55     8.4052       0.03        392       2388      100.0   \n",
       "1    8139.62     8.3803       0.03        393       2388      100.0   \n",
       "2    8130.10     8.4441       0.03        393       2388      100.0   \n",
       "3    8132.90     8.3917       0.03        391       2388      100.0   \n",
       "4    8129.54     8.4031       0.03        390       2388      100.0   \n",
       "\n",
       "   Sensor_20  Sensor_21  \n",
       "0      38.86    23.3735  \n",
       "1      39.02    23.3916  \n",
       "2      39.08    23.4166  \n",
       "3      39.00    23.3737  \n",
       "4      38.99    23.4130  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train= pd.read_csv('data/train_FD001.txt', sep=\" \", header=None)\n",
    "test = pd.read_csv('data/test_FD001.txt', sep=\" \", header=None)\n",
    "print(\"train shape: \", train.shape, \"test shape: \", test.shape)\n",
    "# drop pesky NULL columns\n",
    "train.drop(train.columns[[26, 27]], axis=1, inplace=True)\n",
    "test.drop(test.columns[[26, 27]], axis=1, inplace=True)\n",
    "# name columns\n",
    "train.columns = [column_names]\n",
    "test.columns = [column_names]\n",
    "train[train['UnitNumber'] == 1].head(5)\n",
    "test[test['UnitNumber'] == 1].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitNumber</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>Op_Setting_1</th>\n",
       "      <th>Op_Setting_2</th>\n",
       "      <th>Op_Setting_3</th>\n",
       "      <th>Sensor_1</th>\n",
       "      <th>Sensor_2</th>\n",
       "      <th>Sensor_3</th>\n",
       "      <th>Sensor_4</th>\n",
       "      <th>Sensor_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor_13</th>\n",
       "      <th>Sensor_14</th>\n",
       "      <th>Sensor_15</th>\n",
       "      <th>Sensor_16</th>\n",
       "      <th>Sensor_17</th>\n",
       "      <th>Sensor_18</th>\n",
       "      <th>Sensor_19</th>\n",
       "      <th>Sensor_20</th>\n",
       "      <th>Sensor_21</th>\n",
       "      <th>Target_Remaining_Useful_Life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UnitNumber  Cycle  Op_Setting_1  Op_Setting_2  Op_Setting_3  Sensor_1  \\\n",
       "0           1      1       -0.0007       -0.0004         100.0    518.67   \n",
       "1           1      2        0.0019       -0.0003         100.0    518.67   \n",
       "2           1      3       -0.0043        0.0003         100.0    518.67   \n",
       "3           1      4        0.0007        0.0000         100.0    518.67   \n",
       "4           1      5       -0.0019       -0.0002         100.0    518.67   \n",
       "\n",
       "   Sensor_2  Sensor_3  Sensor_4  Sensor_5              ...               \\\n",
       "0    641.82   1589.70   1400.60     14.62              ...                \n",
       "1    642.15   1591.82   1403.14     14.62              ...                \n",
       "2    642.35   1587.99   1404.20     14.62              ...                \n",
       "3    642.35   1582.79   1401.87     14.62              ...                \n",
       "4    642.37   1582.85   1406.22     14.62              ...                \n",
       "\n",
       "   Sensor_13  Sensor_14  Sensor_15  Sensor_16  Sensor_17  Sensor_18  \\\n",
       "0    2388.02    8138.62     8.4195       0.03        392       2388   \n",
       "1    2388.07    8131.49     8.4318       0.03        392       2388   \n",
       "2    2388.03    8133.23     8.4178       0.03        390       2388   \n",
       "3    2388.08    8133.83     8.3682       0.03        392       2388   \n",
       "4    2388.04    8133.80     8.4294       0.03        393       2388   \n",
       "\n",
       "   Sensor_19  Sensor_20  Sensor_21  Target_Remaining_Useful_Life  \n",
       "0      100.0      39.06    23.4190                           191  \n",
       "1      100.0      39.00    23.4236                           190  \n",
       "2      100.0      38.95    23.3442                           189  \n",
       "3      100.0      38.88    23.3739                           188  \n",
       "4      100.0      38.90    23.4044                           187  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_cycle = train.groupby('UnitNumber')['Cycle'].max().reset_index()\n",
    "max_cycle.columns = ['UnitNumber', 'MaxOfCycle']\n",
    "# merge the max cycle back into the original frame\n",
    "train_merged = train.merge(max_cycle, left_on='UnitNumber', right_on='UnitNumber', how='inner')\n",
    "# calculate RUL for each row\n",
    "Target_Remaining_Useful_Life = train_merged[\"MaxOfCycle\"] - train_merged[\"Cycle\"]\n",
    "train_with_target = train_merged[\"Target_Remaining_Useful_Life\"] = Target_Remaining_Useful_Life\n",
    "# remove unnecessary column\n",
    "train_with_target = train_merged.drop(\"MaxOfCycle\", axis=1)\n",
    "train_with_target[train_with_target['UnitNumber'] == 1].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 27)\n",
      "(20631, 22)\n"
     ]
    }
   ],
   "source": [
    "print(train_with_target.shape)\n",
    "leakage_to_drop = ['UnitNumber', 'Cycle', 'Op_Setting_1', 'Op_Setting_2', 'Op_Setting_3']  \n",
    "train_no_leakage = train_with_target.drop(leakage_to_drop, axis = 1)\n",
    "print(train_no_leakage.shape)\n",
    "# set up features and target variable \n",
    "y = train_no_leakage['Target_Remaining_Useful_Life']\n",
    "X = train_no_leakage.drop(['Target_Remaining_Useful_Life'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor_1</th>\n",
       "      <th>Sensor_2</th>\n",
       "      <th>Sensor_3</th>\n",
       "      <th>Sensor_4</th>\n",
       "      <th>Sensor_5</th>\n",
       "      <th>Sensor_6</th>\n",
       "      <th>Sensor_7</th>\n",
       "      <th>Sensor_8</th>\n",
       "      <th>Sensor_9</th>\n",
       "      <th>Sensor_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor_12</th>\n",
       "      <th>Sensor_13</th>\n",
       "      <th>Sensor_14</th>\n",
       "      <th>Sensor_15</th>\n",
       "      <th>Sensor_16</th>\n",
       "      <th>Sensor_17</th>\n",
       "      <th>Sensor_18</th>\n",
       "      <th>Sensor_19</th>\n",
       "      <th>Sensor_20</th>\n",
       "      <th>Sensor_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.36</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9046.19</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.75</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>9044.07</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.26</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>9052.94</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.45</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>9049.48</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.00</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9055.15</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor_1  Sensor_2  Sensor_3  Sensor_4  Sensor_5  Sensor_6  Sensor_7  \\\n",
       "0    518.67    641.82   1589.70   1400.60     14.62     21.61    554.36   \n",
       "1    518.67    642.15   1591.82   1403.14     14.62     21.61    553.75   \n",
       "2    518.67    642.35   1587.99   1404.20     14.62     21.61    554.26   \n",
       "3    518.67    642.35   1582.79   1401.87     14.62     21.61    554.45   \n",
       "4    518.67    642.37   1582.85   1406.22     14.62     21.61    554.00   \n",
       "\n",
       "   Sensor_8  Sensor_9  Sensor_10    ...      Sensor_12  Sensor_13  Sensor_14  \\\n",
       "0   2388.06   9046.19        1.3    ...         521.66    2388.02    8138.62   \n",
       "1   2388.04   9044.07        1.3    ...         522.28    2388.07    8131.49   \n",
       "2   2388.08   9052.94        1.3    ...         522.42    2388.03    8133.23   \n",
       "3   2388.11   9049.48        1.3    ...         522.86    2388.08    8133.83   \n",
       "4   2388.06   9055.15        1.3    ...         522.19    2388.04    8133.80   \n",
       "\n",
       "   Sensor_15  Sensor_16  Sensor_17  Sensor_18  Sensor_19  Sensor_20  Sensor_21  \n",
       "0     8.4195       0.03        392       2388      100.0      39.06    23.4190  \n",
       "1     8.4318       0.03        392       2388      100.0      39.00    23.4236  \n",
       "2     8.4178       0.03        390       2388      100.0      38.95    23.3442  \n",
       "3     8.3682       0.03        392       2388      100.0      38.88    23.3739  \n",
       "4     8.4294       0.03        393       2388      100.0      38.90    23.4044  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(X))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "rf = ensemble.RandomForestRegressor()\n",
    "single_rf = ensemble.RandomForestRegressor(n_estimators = 200, max_depth = 15)\n",
    "single_rf.fit(X, y)\n",
    "y_pred = single_rf.predict(X)\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp8AAAIyCAYAAACNaqE4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzs3XmcjXX/x/H3mY1hyDZarENmEsYu\nZRlhyI0sYcaMUdlSoR+SpcJtmdRdSm4V3Vka+9KmSA2yl6jBWG+SrZoso8xgxsy5fn94OHdjDE6d\n8z3m9Ho+Hj0ec53rOt/P5zrj8O57bTbLsiwBAAAABvh4ugEAAAD8fRA+AQAAYAzhEwAAAMYQPgEA\nAGAM4RMAAADGED4BAABgDOETgMd88MEHCgsLu+F/iYmJbu8lIyNDM2fOdHud/OLK72b27NnX3e6b\nb75RWFiYJk6caKYxAPmen6cbAIAGDRqoQYMGea4PCQlxew89evTQ4cOH1atXL7fX8iZlypTRgAED\nVLNmTU+3AiCfIHwC8LgGDRpo4MCBHu3h9OnTHq2fX5UtW9bjvzsA+QuH3QEAAGAM4RNAvmJZlhYs\nWKBOnTopPDxc9evXV//+/bVnz55c26anp2vatGnq0KGDateurRo1aqhVq1Z65ZVXdP78eUnS8ePH\nFRYWphMnTujcuXMKCwvTiBEjJElxcXEKCwvT77//nmPcK+956qmnHK+NGDFCYWFh2rlzp/7xj3+o\nRo0aio6O1pUnGB85ckTPPvusHnjgAVWvXl1t2rTR9OnTdenSpRvu85XzL1euXKnevXurRo0aevDB\nB3Xs2DFJ0oEDBzRs2DBFRESoevXqqlOnjqKjo7Vq1aoc40ydOlVhYWE6dOiQJk+erGbNmql69epq\n27atFixYcMM+zp07p44dO+qee+7RkiVLJF37nM+4uDg1b95cv/zyi4YOHar77rtPNWvWVGxsrL75\n5ptc4x49elRDhgzRAw88oNq1a6tv3746dOiQIiMjFRcXd8O+AOQvHHYHkK8MHz5cH3/8sapUqaLo\n6GhduHBBK1euVHR0tKZPn677779fkpSVlaXHH39cO3fuVOPGjdW4cWOlp6drzZo1eu+993T8+HG9\n+eabKlq0qAYMGKA5c+YoIyND/fr1U9WqVf90f08++aRq1KihRo0aqVChQrLZbNq9e7ceffRRXbx4\nUa1atdJdd92lbdu2afLkyfr22281ffp0+fr63nDsCRMmqHTp0oqLi9Px48dVrlw57dy5U3FxcQoI\nCFCrVq1UokQJHTlyRKtXr9agQYP0zjvv6MEHH8wxzrBhw/TTTz+pVatW8vPz0yeffKKxY8eqUKFC\n6tChwzVrX7x4UU888YT27t2r0aNHq2vXrtftNT09XTExMQoMDFTHjh116tQprVixQr1799aKFStU\nvnx5SZdDeXR0tM6ePauWLVuqbNmyWrt2rWJiYmS323XHHXfc5CcPIL8gfALwuK1bt2rq1KnXXNep\nUyeVLVtWkrRy5Up9/PHHateunV5++WX5+V3+K6xfv37q0qWLhg8frsTERAUEBGjVqlXasWOH+vfv\nr8GDBzvGe/bZZ9W6dWslJibqwoULKlq0qAYOHKgPP/xQv//++18+f7FOnTo59sWyLI0YMUKZmZla\nuHChqlev7lj30ksvafbs2Vq4cKFiY2NvOLafn5/mz5+vwMBAx2tTpkxRVlaWPvjgA1WuXNnx+ooV\nKzR48GB9+umnucLn2bNntWLFCpUoUUKS1K5dO3Xv3l2LFy++Zvi8dOmSBg4cqO3bt2vkyJE31evZ\ns2dVt25dTZkyRf7+/pKkKlWq6PXXX9eHH36oZ555xvEZnDlzRlOmTNFDDz0kSRo8eLAee+wxbd++\n/YZ1AOQ/hE8AHrd161Zt3br1musaNGjgCJ9Lly6VJD3//POO4ClJ5cqVU3R0tN555x1t3rxZzZo1\n07333qsJEyaoZcuWOcYLCgrSvffeq/Xr1+u3337LEeRcoXXr1jmWd+zYoQMHDig2NjZH8JSkZ555\nRvPmzdMHH3xwU4EuIiIiV7+PPfaYHnnkkRzBU5Luu+8+Sde+kOqRRx5xBE/pcmAuWrSofvzxx1zb\nWpal4cOHa/369Ro6dKgee+yxG/Z5Ra9evRzB80r/r7/+uqPOmTNntG7dOtWrV88RPCUpICBAzz77\nrLp3737TtQDkH4RPAB43YMCAm5px3L17twoUKKB58+blWnf48GFJ0t69e9WsWTOFhIQoJCREGRkZ\n2rFjhw4fPqyjR49q9+7djqCbnZ3t2h3R5VsPXd2zdPm8xmvN7hYuXFj79++XZVmy2WxOjS1JTZo0\nkSSdPHlS+/bt09GjR3X48GHHrOG19vFat64KCgpSWlpartdnzpypX3/9VT4+PmratOl1+7taxYoV\nc9WQpMzMTEmXPxu73a7w8PBc761Zs2aO/8EA4D34ZgPIN86dO6esrCz9+9//znOb3377TZJkt9s1\nffp0zZo1y/FayZIlVbt2bZUpU0aHDh1yXAzkSgULFsyxfOVipQ0bNmjDhg15vi89Pd0RzvJSoECB\nXK/9/PPPGj9+vNasWSPLsuTj46OKFSuqbt2617wIS7o8s3g1m812zc/j119/VfPmzbVmzRq98MIL\nWrx4sXx8bu5a1avrXAnXV+qkpqZKkkqVKpXrvb6+vjlmZwF4D8IngHyjUKFCKly4sL766qsbbjtz\n5ky98cYbatCggfr27auqVasqODhYktSnTx8dOnToputeHcouXrzoVM+SNHHiRHXp0uWm33ezffXr\n108HDx7UE088oZYtW6pKlSoqWLCgTp065bgi/a/o0KGDXnnlFQ0dOlSffvqp5s6dq549e7qg+//N\nhF5rxlW6HMgBeB9utQQg3wgLC9Mvv/yikydP5lq3du1avf7669q3b58k6dNPP5Wvr6/efvttNW3a\n1BE8LcvSDz/84Pj5eq7M3F25LdMVR48edapnSUpOTs617tKlS5o0aZISEhJuerw/2r9/vw4cOKDI\nyEgNHjxYNWrUcMy8XgnXf3V2995775V0+VZSRYoU0RtvvKFffvnlL415RbVq1WSz2bRz585c6w4e\nPEj4BLwU4RNAvtGpUydZlqXx48c7zhuULh8aHjt2rGbMmOGYaSxQoICys7N15syZHGO89dZbOnHi\nhKTLt2O6wt/fP8ey9L9zI9euXet4LSMjQ++9995N91y/fn2VLVtWS5cu1ffff59j3YwZMzRr1izH\neaHOuhKOr76o6OzZs3rllVckKdc+/VnBwcEaNGiQ0tPTNW7cOJeMefvtt6tRo0bavHmz1q1b53g9\nMzNT//rXv1xSA8Cth8PuAPKNzp07a82aNVq1apX279+vJk2aKCsrSytXrtTZs2c1dOhQx/0jH374\nYSUlJal79+5q06aN/P399c0332j37t0qWbKkTp8+rbNnzzrGLl26tH788Uc9++yzaty4sTp27Kgu\nXbpo/vz5io+P144dO1S8eHGtXr1aRYoUcYTcG/H19dXLL7+svn37qkePHmrRooXKlSun5ORkff31\n1ypbtqyGDBnypz6PihUrKjw8XNu2bVNMTIzq1Kmj1NRUJSYmKjMzU4GBgY7zKl0hNjZWH374oVav\nXq0vv/xSkZGRf3nM559/XlFRUXryySfVsmVL3X777dq0aZPjfxpu9vxSAPkH32oA+YbNZtObb76p\n559/XoGBgVqyZIlWrlypu+++W9OmTVO/fv0c28bExOjFF19UsWLFtGTJEi1fvlyFCxfW5MmTHTN3\nf5xtGzZsmKpUqaLPP/9cH3/8sSTpnnvu0YwZM1S9enWtXLlSn3zyie6//37Nnj37pm4Kf0W9evW0\nZMkSPfTQQ9q2bZvef/99/fTTT4qLi9OiRYtUunTpP/V5+Pj46K233lLnzp11/PhxJSQkaNu2bWra\ntKmWLVumRo0a6ccff3TqNIHr8fX11dixY2Wz2TR+/Pg8z9V0RqVKlbRgwQJFRERo8+bNWrJkicqX\nL685c+ZIkstvhQXA82yWOy73BADgBux2u44dO6a77rorx/1AJenYsWNq2bKlunfvrrFjx3qmQQBu\nwcwnAMAjbDabOnbsqPbt2+c4h1eS47zaKzfLB+A9OOcTAOARNptN0dHRmjlzph5++GE1bdpUvr6+\n+u6775SUlKTGjRvnePIRAO/AYXcAgMfY7XYtW7ZMS5Ys0eHDh5WVlaWyZcuqffv2evzxx3MdjgeQ\n/xE+AQAAYAznfAIAAMAYrznn8+TJc0brFS9eSKmp52+8IfX+9vW8ed+oRz3qea6eN+8b9fJ/veDg\nInmuY+bzT/Lzu/l7/FHv713Pm/eNetSjnufqefO+US//17sewicAAACMIXwCAADAGMInAAAAjCF8\nAgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBiPPdvdbrdr7Nix2r9/\nvwICAjRhwgRVqFDBsX7ChAn67rvvVLhwYUnSW2+9pSJF8n5OKAAAAG59HgufiYmJyszM1KJFi5SU\nlKRJkybp7bffdqzfvXu3/vOf/6hEiRKeahEAAAAu5rHD7tu3b1eTJk0kSbVq1VJycrJjnd1u15Ej\nRzR69GhFR0dr6dKlnmoTAAAALuSxmc+0tDQFBQU5ln19fZWVlSU/Pz+dP39ePXr00OOPP67s7Gz1\n7NlT1atX1z333JPneMWLF5Kfn6+J1h2Cg82eBkC9/FvPm/eNetSjnufqefO+US//18uLx8JnUFCQ\n0tPTHct2u11+fpfbCQwMVM+ePRUYGChJatiwofbt23fd8Jmaet69DV8lOLiITp48Rz3q3VK1qEc9\n6v196nnzvlHPO+rlxWOH3evUqaP169dLkpKSkhQaGupY9+OPPyomJkbZ2dm6dOmSvvvuO1WrVs1T\nrQIAAMBFPDbzGRkZqU2bNik6OlqWZSk+Pl6zZs1S+fLl1aJFC7Vv317dunWTv7+/OnTooCpVqniq\nVQAAALiIx8Knj4+Pxo0bl+O1ypUrO37u27ev+vbta7otAAAAuBE3mQcAAIAxhE8AAAAYQ/gEAACA\nMR475/NWVLq0s/e/urntf/3V3K0NAAAAbmXMfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAA\nwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicA\nAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8\nAgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAY\nwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAA\njCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIA\nAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMIn\nAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwh\nfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADA\nGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBiPhU+7\n3a7Ro0crKipKcXFxOnLkyDW36dOnjxYsWOCBDgEAAOBqHgufiYmJyszM1KJFizR06FBNmjQp1zZv\nvPGGfvvtNw90BwAAAHewWZZleaLwSy+9pPDwcLVt21aS1KRJE23YsMGx/vPPP9fevXvl5+enUqVK\nqXv37tcdLysrW35+vn+pJ5vtL709T575hAEAAG49fp4qnJaWpqCgIMeyr6+vsrKy5OfnpwMHDujT\nTz/Vm2++qWnTpt3UeKmp513QVREXjJHbyZPn/vIYwcFFXDIO9czX8+Z9ox71qOe5et68b9Tzjnp5\n8Vj4DAoKUnp6umPZbrfLz+9yOx999JFSUlL06KOP6sSJE/L391eZMmXUtGlTT7ULAAAAF/BY+KxT\np47Wrl2rf/zjH0pKSlJoaKhj3XPPPef4eerUqSpVqhTBEwAAwAt4LHxGRkZq06ZNio6OlmVZio+P\n16xZs1S+fHm1aNHCU20BAADAjTwWPn18fDRu3Lgcr1WuXDnXdgMHDjTVEgAAANyMm8wDAADAGMIn\nAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwh\nfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADA\nGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAA\nAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwC\nAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjC\nJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACM\nIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAA\nwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicA\nAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8\nAgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjPFY+LTb7Ro9erSioqIUFxenI0eO\n5Fg/b948PfLII+rSpYvWrl3roS4BAADgSn6eKpyYmKjMzEwtWrRISUlJmjRpkt5++21J0pkzZzR/\n/nx99NFHysjIUNu2bdWsWTPZbDZPtQsAAAAX+FPhMysrS7t27dLPP/+sBg0aqGDBgsrOztZtt912\n02Ns375dTZo0kSTVqlVLycnJjnUlSpTQxx9/LD8/P504cUJFixYleAIAAHgBp8PnypUrNXHiRJ0+\nfVqSNHPmTGVmZuqZZ57RgAED1KdPn5saJy0tTUFBQY5lX19fZWVlyc/vckt+fn6aO3eupk6dqri4\nuBuOV7x4Ifn5+Tq7O0YEBxe5pcahnvl63rxv1KMe9TxXz5v3jXr5v15enAqfGzdu1NChQ1WnTh31\n6dNHkyZNkiSVLVtWoaGheu211xQcHKwOHTrccKygoCClp6c7lu12uyN4XtGjRw9169ZNffv21ddf\nf62GDRvmOV5q6nlndiUP7vmlnDx57i+PERxcxCXjUM98PW/eN+pRj3qeq+fN+0Y976iXF6cuOJo2\nbZqqV6+u999/P0fArFy5subPn6/atWtrzpw5NzVWnTp1tH79eklSUlKSQkNDHet++OEHDRgwQJZl\nyd/fXwEBAfLx4cJ8AACA/M6pmc+9e/dq8ODB1wyCfn5+ateunf71r3/d1FiRkZHatGmToqOjZVmW\n4uPjNWvWLJUvX14tWrTQPffco6ioKNlsNjVp0kQNGjRwplUAAADcgpwKn/7+/srKyspz/dmzZ+Xv\n739TY/n4+GjcuHE5XqtcubLj5wEDBmjAgAHOtAcAAIBbnFPHshs0aKClS5cqIyMj17pff/1V8+fP\nV926dV3WHAAAALyLUzOfQ4YMUVRUlB5++GE1bdpUNptNq1ev1ldffaUPP/xQmZmZGjRokLt6BQAA\nQD7n1Mxn5cqVNW/ePJUuXVoJCQmyLEtz587VnDlzVL58ec2ePVtVq1Z1V68AAADI55y+z2dYWJgS\nEhJ09uxZHT16VHa7XWXKlFFwcLA7+gMAAIAXcfr+RcnJyRo8eLCys7MVHh6uWrVqaebMmRo0aJAO\nHTrkjh4BAADgJZwKn9u2bVNMTIw2bdqk1NRUx+vBwcHavn27unTpon379rm8SQAAAHgHp8LnlClT\nFBISoi+++EJ333234/VevXppxYoVKleunF577TWXNwkAAADv4FT43Lt3r6KiolSsWLFc62677TZ1\n69ZNO3fudFlzAAAA8C5OhU8/P78ch9uvlpaWJrvd/pebAgAAgHdyKnzed999mjt3ro4dO5ZrXUpK\niubOnctjMAEAAJAnp2619Mwzz6hr166Om8xXrFhRNptNR48e1bp162Sz2TRkyBB39QoAAIB8zqnw\nWalSJX3wwQd6/fXXtX79eq1atUqSVLBgQTVq1EhDhgzJ8Xx2AAAA4I+cvsl8hQoV9MYbb8iyLKWm\npsput6t48eLy9fV1R38AAADwIk6HzytsNptKlCjhyl4AAADg5ZwOnwsWLNDy5ct16tQpZWdn51pv\ns9mUmJjokuYAAADgXZwKn//+97/173//W7fddptCQkLk7+/vrr4AAADghZwKn8uWLVODBg30n//8\nRwEBAe7qCQAAAF7Kqft8nj59Wu3btyd4AgAA4E9xKnxWqVJFhw8fdlcvAAAA8HJOhc//+7//0+LF\ni7Vu3Tp39QMAAAAv5tQ5n3PmzFGhQoXUv39/FSxYUMWLF5fNZsuxDVe7AwAAIC9Ohc+MjAxVqFBB\nFSpUcFc/AAAA8GJOhc+EhAR39QEAAIC/AafO+bwZe/bscfWQAAAA8BJOzXxeunRJM2bM0BdffKHz\n58/Lbrc71mVnZys9PV1paWnau3evyxsFAABA/ufUzOcbb7yhqVOn6rffflNgYKBOnDihO++8U35+\nfvrll1906dIlPf/88+7qFQAAAPmcU+Hz888/V4MGDbRmzRq9++67kqTRo0dr1apVmj59urKysnjk\nJgAAAPLkVPhMSUlRq1at5OPjo9tvv10lS5bU999/L0mKiIhQp06dtHjxYrc0CgAAgPzPqfBZsGDB\nHDOb5cuX14EDBxzL4eHhOnbsmOu6AwAAgFdxKnxWrVpV69evdyxXqlTJMfMpXZ4Zvfqm8wAAAMAV\nToXP2NhYrV69WjExMUpLS1Pbtm21Z88ejRw5Uu+++65mz56tGjVquKtXAAAA5HNO3WrpoYce0vjx\n4zVr1iwFBgbqgQceUN++fR0XH911110aMWKEWxoFAABA/udU+JSkrl27qmvXro7loUOHqnv37vrt\nt99UuXJlBQQEuLRBAAAAeA+nDrv37NlTW7ZsyfX6XXfdpapVq2rjxo1q27aty5oDAACAd7nuzOeF\nCxeUmprqWN66dasiIyNVoUKFXNva7XatX79ex48fd32XAAAA8Ao3DJ8dO3bUuXPnJEk2m03x8fGK\nj4+/5vaWZalRo0au7xIAAABe4brhs0SJEvrXv/6lXbt2ybIsTZs2TZGRkQoLC8u1rY+Pj0qUKMFh\ndwAAAOTphhccRUREKCIiQpKUnJysPn36qGbNmm5vDAAAAN7HqQuO9u3bp40bN7qrFwAAAHg5p8Jn\namqqgoOD3dULAAAAvJxT4bN9+/ZatGgRV7QDAADgT3HqJvM+Pj764Ycf1Lp1a5UvX14lS5aUj0/O\n/Gqz2TRnzhyXNgkAAADv4FT43LRpk4oXLy5JysjI0E8//eSWpgAAAOCdnAqfa9ascVcfAAAA+Btw\n+tnukpSdna3k5GSdOHFCAQEBuvPOO1WtWjVX9wYAAAAv43T4XLt2rf75z38qJSVFlmVJunyeZ+nS\npTVmzBg1b97c5U0CAADAOzgVPrdt26aBAweqZMmSGjx4sCpXrizLsvTDDz9o/vz5GjRokN5//33V\nqVPHXf0CAAAgH3MqfE6dOlVlypTR0qVLVaRIkRzrYmJi9Mgjj+jtt9/Wu+++69ImAQAA4B2cus/n\nzp071bVr11zBU5KCgoLUpUsX7dixw2XNAQAAwLs4FT5vxGaz6dKlS64cEgAAAF7EqfBZs2ZNLV26\nVOfPn8+1Li0tTUuWLFGNGjVc1hwAAAC8i1PnfA4YMEA9e/ZUu3bt1KNHD1WsWFGSHBccpaSk6J//\n/Kc7+gQAAIAXcCp81qtXT1OnTtW4ceP0yiuvyGazSZIsy1JwcLBef/11NWzY0C2NAgAAIP9z+j6f\nLVq0ULNmzbR7924dP35cklSmTBlVq1ZNfn5/6p71AAAA+Jv4U2nR19dXZcuWlY+Pj+NngicAAABu\nxOnEuG3bNr366qvauXOn4wlHvr6+atiwoZ577jmFhoa6vEkAAAB4B6fC5zfffKPevXurUKFCiomJ\nUcWKFZWdna0ff/xRy5cvV/fu3bVgwQICKAAAAK7JqfD5xhtvqEyZMlqwYIFKlCiRY93TTz+tbt26\nafLkyXrnnXdc2iQAAAC8g1P3+dy3b5+6d++eK3hKUqlSpRQTE6Nvv/3WZc0BAADAuzgVPkuWLKnT\np0/nuT4jI0NBQUF/uSkAAAB4J6fCZ//+/fX+++9rzZo1udbt2LFD77//vp5++mmXNQcAAADv4tQ5\nn0lJSSpZsqSefvppVapUSZUrV5a/v7+OHTumXbt2KSAgQJ9++qk+/fRTx3tsNpvmzJnj8sYBAACQ\n/zgVPjdv3ixJuvPOO3XhwgUlJyc71t15552S5LjxPAAAAHA1p8LntQ63AwAAADfLqXM+AQAAgL/C\nqZnPzMxMvfvuu9q0aZNOnjwpu92eaxubzabExESXNQgAAADv4VT4nDhxohYtWqQ77rhDZcqUkY8P\nE6cAAAC4eU6Fzy+//FLt2rXTq6++6q5+AAAA4MWcmrrMzs5W/fr13dULAAAAvJxT4bN169b68ssv\n3dULAAAAvJxTh92HDx+ufv36KTo6Wi1btlTJkiVls9lybdexY0eXNQgAAADv4VT43L59u/bs2aML\nFy4oKSnpmtvYbDbCJwAAAK5QVgf7AAAf2ElEQVTJqfD5yiuvqFChQho2bJhCQkLk6+vrrr4AAADg\nhZwKn0ePHtWwYcMUExPjrn4AAADgxZy64CgkJETnzp1zVy8AAADwck6Fz0GDBmnOnDlat27dNZ9u\nBAAAAFyPU4fdlyxZooCAAPXv318FChRQsWLFcp33yeM1AQAAkBenwmd6eroqVqyoihUruqkdAAAA\neDOnwmdCQoK7+gAAAMDfwHXDZ4sWLTRq1Ci1aNHCsXwjHHYHAABAXq4bPu+66y4VKlQoxzIAAADw\nZ103fF59mJ3D7gAAAPgrnLrVEgAAAPBXED4BAABgDOETAAAAxhA+AQAAYAzhEwAAAMY4dZN5V7Lb\n7Ro7dqz279+vgIAATZgwQRUqVHCsnz17tj777DNJUkREhAYMGOCpVgEAAOAiHpv5TExMVGZmphYt\nWqShQ4dq0qRJjnXHjh3TJ598ooULF2rRokXauHGj9u3b56lWAQAA4CIem/ncvn27mjRpIkmqVauW\nkpOTHevuuOMO/ec//5Gvr68kKSsrSwUKFPBInwAAAHAdj4XPtLQ0BQUFOZZ9fX2VlZUlPz8/+fv7\nq0SJErIsS6+88oruvfdehYSEXHe84sULyc/P191t/ynBwUVuqXGoZ76eN+8b9ahHPc/V8+Z9o17+\nr5cXj4XPoKAgpaenO5btdrv8/P7XTkZGhkaNGqXChQtrzJgxNxwvNfW8C7pyzy/l5Mlzf3mM4OAi\nLhmHeubrefO+UY961PNcPW/eN+p5R728eOyczzp16mj9+vWSpKSkJIWGhjrWWZalp556SmFhYRo3\nbpzj8DsAAADyN4/NfEZGRmrTpk2Kjo6WZVmKj4/XrFmzVL58edntdm3dulWZmZnasGGDJGnIkCGq\nXbu2p9oFAACAC3gsfPr4+GjcuHE5XqtcubLj5127dpluCQAAAG7GTeYBAABgDOETAAAAxhA+AQAA\nYAzhEwAAAMYQPgEAAGAM4RMAAADGED4BAABgDOETAAAAxhA+AQAAYAzhEwAAAMYQPgEAAGAM4RMA\nAADGED4BAABgDOETAAAAxhA+AQAAYAzhEwAAAMYQPgEAAGAM4RMAAADGED4BAABgDOETAAAAxhA+\nAQAAYAzhEwAAAMYQPgEAAGAM4RMAAADGED4BAABgDOETAAAAxhA+AQAAYAzhEwAAAMYQPgEAAGAM\n4RMAAADGED4BAABgDOETAAAAxhA+AQAAYAzhEwAAAMYQPgEAAGAM4RMAAADGED4BAABgDOETAAAA\nxhA+AQAAYAzhEwAAAMYQPgEAAGAM4RMAAADGED4BAABgDOETAAAAxhA+AQAAYAzhEwAAAMYQPgEA\nAGAM4RMAAADGED4BAABgDOETAAAAxhA+AQAAYAzhEwAAAMYQPgEAAGAM4RMAAADGED4BAABgDOET\nAAAAxhA+AQAAYAzhEwAAAMb4ebqBv7PSpYs4+Y6b2/7XX8853wwAAIABzHwCAADAGMInAAAAjCF8\nAgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAY\nwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAA\njCF8AgAAwBjCJwAAAIwhfAIAAMAYwicAAACMIXwCAADAGMInAAAAjCF8AgAAwBjCJwAAAIzxWPi0\n2+0aPXq0oqKiFBcXpyNHjuTa5syZM2rVqpUyMjI80CEAAABczWPhMzExUZmZmVq0aJGGDh2qSZMm\n5Vi/YcMG9erVS6dOnfJQhwAAAHA1j4XP7du3q0mTJpKkWrVqKTk5Ocd6Hx8fzZo1S8WKFfNEewAA\nAHADP08VTktLU1BQkGPZ19dXWVlZ8vO73FKjRo2cGq948ULy8/N1aY+uEhxcJF/Wy69934r1vHnf\nqEc96nmunjfvG/Xyf728eCx8BgUFKT093bFst9sdwfPPSE0974Ku3PNLOXny3C1S7+YFBxdxyTjU\n8+59ox71qOe5et68b9Tzjnp58dhh9zp16mj9+vWSpKSkJIWGhnqqFQAAABjisZnPyMhIbdq0SdHR\n0bIsS/Hx8Zo1a5bKly+vFi1aeKotAAAAuJHHwqePj4/GjRuX47XKlSvn2m7NmjWmWgIAAICbcZN5\nAAAAGOOxmU+YV7q0sxc43dz2v/5q7gRmAACQvzHzCQAAAGMInwAAADCG8AkAAABjCJ8AAAAwhvAJ\nAAAAYwifAAAAMIbwCQAAAGMInwAAADCG8AkAAABjCJ8AAAAwhvAJAAAAYwifAAAAMIbwCQAAAGMI\nnwAAADCG8AkAAABjCJ8AAAAwhvAJAAAAYwifAAAAMIbwCQAAAGMInwAAADCG8AkAAABjCJ8AAAAw\nhvAJAAAAYwifAAAAMIbwCQAAAGMInwAAADCG8AkAAABjCJ8AAAAwhvAJAAAAYwifAAAAMIbwCQAA\nAGMInwAAADCG8AkAAABjCJ8AAAAwhvAJAAAAYwifAAAAMIbwCQAAAGMInwAAADCG8AkAAABjCJ8A\nAAAwhvAJAAAAYwifAAAAMIbwCQAAAGMInwAAADCG8AkAAABjCJ8AAAAwhvAJAAAAY/w83QC8V+nS\nRZx8x81t/+uv55xvBgAA3BKY+QQAAIAxhE8AAAAYQ/gEAACAMYRPAAAAGEP4BAAAgDGETwAAABhD\n+AQAAIAx3OcTXsH5e4pKf+W+ou66h2le9QAA8BbMfAIAAMAYwicAAACMIXwCAADAGMInAAAAjOGC\nIyAf4AInAIC3YOYTAAAAxjDzCSAXd820MssKAGDmEwAAAMYQPgEAAGAMh90BeJzpw/ycVgAAnsPM\nJwAAAIwhfAIAAMAYwicAAACM4ZxPAHAzzjEFgP8hfAKAlyHsAriVET4BAH8JYReAMzjnEwAAAMYQ\nPgEAAGAM4RMAAADGED4BAABgDOETAAAAxhA+AQAAYAzhEwAAAMYQPgEAAGAMN5kHAOQr3NQeyN+Y\n+QQAAIAxhE8AAAAYQ/gEAACAMYRPAAAAGOOx8Gm32zV69GhFRUUpLi5OR44cybF+8eLF6ty5s7p1\n66a1a9d6qEsAAAC4kseudk9MTFRmZqYWLVqkpKQkTZo0SW+//bYk6eTJk0pISNCyZcuUkZGhmJgY\nNWrUSAEBAZ5qFwAAAC7gsfC5fft2NWnSRJJUq1YtJScnO9bt3LlTtWvXVkBAgAICAlS+fHnt27dP\n4eHhnmoXAPA35PxtnSRu7QRcn8fCZ1pamoKCghzLvr6+ysrKkp+fn9LS0lSkyP++vIULF1ZaWtp1\nxwsO/jN/QeRkWX95iDxcuzfqua6e+2pRz921qEe9W7me6e+es1zxbx/1qGeax875DAoKUnp6umPZ\nbrfLz8/vmuvS09NzhFEAAADkTx4Ln3Xq1NH69eslSUlJSQoNDXWsCw8P1/bt25WRkaFz587p0KFD\nOdYDAAAgf7JZlnsPKuTFbrdr7NixOnDggCzLUnx8vNavX6/y5curRYsWWrx4sRYtWiTLsvTEE0+o\ndevWnmgTAAAALuSx8AkAAIC/H24yDwAAAGMInwAAADCG8OmEHTt2KC4uTpJ05MgRde/eXTExMRoz\nZozsdrvL6126dElDhw5VdHS0YmJidOjQIZfX+KPs7GyNHDlS0dHRio2N1dGjR91W64+f5RXx8fFa\nsGCB2+sdPHhQ3bt3V3R0tMaOHavs7Gy31JSk6dOnKyoqSp07d9aSJUvcVudan+fy5csVFRXl0jqX\nLl3SsGHDFBMToy5dumj16tVGvgt51Xa3a32u7q6ze/dudenSRTExMRo/frzLP88/1tq7d69iYmIU\nFxen3r1769SpUy6t9UcffPCB4uLiFBcXp27duqlGjRr6/fffXV7nj/t3+vRpPfnkk4qNjVV0dLRb\n/07r2LGjY/9GjhzptjpX/1lp0qSJo+6KFSvcUjMzM1NDhw5Vt27d1KtXL/34449uqSPl3L/Bgwc7\n9q158+YaPHiw2+qePn1aERERbv939urvX7du3dS9e3eNHDnSbX933uiJkh5h4abMmDHDateundW1\na1fLsizriSeesL7++mvLsizrxRdftL744guX1/zyyy+tQYMGWZZlWRs3brQGDBjg8hpX1xsxYoRl\nWZb19ddfW/3793dLnas/y9OnT1u9e/e2WrRoYc2fP9/t9Z588klr69atlmVZ1vDhw93yu7Osy5/h\nE088YWVnZ1tpaWnWm2++6ZY6V++fZVnWnj17rJ49e+Z4zRWWLl1qTZgwwbIsyzpz5owVERFh5LuQ\nV213utbnaqJOp06drO3bt1uWZVmTJ0+2PvroI7fVio2Ntfbs2WNZlmUtWLDAio+Pd1mt6xk7dqy1\ncOFCl4979f4NHz7c+uyzzyzLsqwtW7ZYa9eudXlNy7KsixcvWh06dHDL2H909f4tXrzYeu+999xe\nNyEhwXrhhRcsy7KsQ4cOWb169XJLnby+c2fPnrUefvhhKyUlxS11MzMzraeeespq1aqVdfDgQbfU\nsKzc+/fUU09ZX331lWVZljVkyBBr9erVbqm7atUqa/jw4ZZlWdb333/vtn/bncHM500qX768pk6d\n6ljevXu3GjRoIElq2rSpNm/e7PKaISEhys7Olt1uV1pamuM+qO7SsmVLjR8/XpL0008/qVSpUm6p\nc/VnmZ6eroEDB6pDhw5G6k2dOlX169dXZmamTp48qZIlS7ql7saNGxUaGqqnn35a/fv3V7NmzdxS\n5+r9S01N1auvvqpRo0a5vNZDDz2kZ555xrHs6+tr5LuQV213uvpzNVUnJSVFderUkXT5lnTbt293\nW63JkyeratWqki4f+ShQoIDLauVl165dOnjwoMtn5aXc+/fdd98pJSVFjz32mJYvX+74c+pq+/bt\n04ULF9SrVy/17NlTSUlJbqlz9f4lJyfrq6++UmxsrEaNGnXDh7H8WQcPHlTTpk0lSZUqVXLb7GBe\n37mpU6eqR48eKl26tFvqvvzyy4qOjnbb+FdcvX9Vq1bV2bNnZVmW0tPT3fZv/PWeKOkphM+b1Lp1\n6xx/MCzLks1mk3T5CUznzrn+MWmFChXSiRMn1KZNG7344otGDv/5+flp+PDhGj9+vNtub3X1Z1mu\nXDnVrFnTLbWuVc/X11cnTpxQu3btlJqaqpCQELfUTU1NVXJysqZMmaJ//vOfevbZZ2W54eYSf9y/\n7OxsPf/88xo1apQKFy7s8lqFCxdWUFCQ0tLSNGjQIP3f//2fke9CXrXd6eo/N6bqlCtXTlu3bpUk\nrV27VhcuXHBbrSv/2H733XeaO3euHnvsMZfVysv06dP19NNPu2Xsq/fvxIkTKlq0qGbPnq0777xT\n7777rlvqFixYUL1799Z7773n+K5nZWW5vM7V+xceHq7nnntO8+bNU7ly5TRt2jSX15Quh6S1a9fK\nsiwlJSUpJSXFLacrXes7d/r0aW3ZskWdO3d2eT3p8ukgJUqUcIQzd7p6/ypWrKiJEyeqTZs2On36\ntO677z631M3riZKeRPj8k3x8/vfRpaenq2jRoi6vMXv2bDVu3FirVq3Sxx9/rBEjRigjI8Plda72\n8ssva9WqVXrxxRd1/vx5t9fzhDJlyuiLL75Q9+7dNWnSJLfUKFasmBo3bqyAgABVqlRJBQoU0Jkz\nZ9xS64rdu3fryJEjGjt2rIYMGaKDBw9q4sSJLq3x888/q2fPnurQoYPat29v5LuQV21vFB8fr+nT\np6tfv34qWbKkihcv7tZ6K1as0JgxYzRjxgyVKFHCrbV+//13/fDDD2rYsKFb61xRrFgxNW/eXJLU\nvHlzt834hISE6OGHH5bNZlNISIiKFSumkydPuqXWH0VGRqp69eqOn/fs2eOWOo888oiCgoLUs2dP\nrV27VtWqVXP7kYcrPv/8c7Vr185t9ZYtW6bNmzcrLi5Oe/fu1fDhw4387iRp4sSJmjdvnj7//HN1\n7NjRbf8WXe+Jkp5C+PyT7r33Xn3zzTeSpPXr16tevXour1G0aFHHY0Vvu+02ZWVlufXimI8++kjT\np0+XJAUGBspmsxn7C8ak/v37O06YL1y4cI7w5Ep169bVhg0bZFmWUlJSdOHCBRUrVswtta4IDw/X\nZ599poSEBE2ePFl33323nn/+eZeNf+rUKfXq1UvDhg1Tly5dJJn5LuRV2xutW7dO8fHxmjFjhs6e\nPatGjRq5rdbHH3+suXPnKiEhQeXKlXNbnSu+/fZbPfDAA26vc0XdunW1bt06R+27777bLXWWLl3q\nCA4pKSlKS0tTcHCwW2r9Ue/evbVz505J0pYtW1StWjW31Nm1a5fq1q2rhIQEtWzZ0siflSu2bNni\nOOTvDvPmzXN8B6pWraqXX37ZyO9Ouvzv+pUZydKlS7vlAjzp+k+U9BTPRt98bPjw4XrxxRc1efJk\nVapUyS2HqB977DGNGjVKMTExunTpkgYPHqxChQq5vM4VrVq10siRIxUbG6usrCyNGjXKyDlgpvXr\n108jRoyQv7+/AgMDNWHCBLfUefDBB/Xtt9+qS5cusixLo0ePzvdh/p133tHvv/+ut956S2+99ZYk\n6fnnn9eECRPc+l3Iq/a7776rggULuqWep1SoUEH9+vVTYGCg7rvvPkVERLilTnZ2tiZOnKg777xT\nAwcOlCTVr19fgwYNcks9STp8+LDKli3rtvGvNnz4cL3wwgtauHChgoKC9Nprr7mlTpcuXTRy5Eh1\n795dNptN8fHxRmaWxo4dq/Hjx8vf31+lSpVynLPvahUqVNCUKVM0c+ZMFSlSxOVHU67n8OHDRsOu\nSRMmTNDgwYPl5+cnf39/t/3+IiMjtWnTJkVHRzueKOlpPOEIAAAAxnDYHQAAAMYQPgEAAGAM4RMA\nAADGED4BAABgDOETAAAAxhA+AbhVXFyc40bft+J4rnTlwRDh4eF69dVX89wuLS0txwMHRowYobCw\nMLf3t3z5cjVv3lw1atTQ0KFD3VIjMzNTKSkpbhkbgHcgfAJwq/79+7vlOfO3mv379+ull15SmTJl\n9OKLL+Z5v9Pk5GS1adNG//3vf432l5qaqpEjRyogIEAvvPCCunbt6vIaJ06cUPv27bVp0yaXjw3A\ne3CTeQBu5c4n9NxKDhw4IEl64oknrjsze+DAAf3666+m2nI4fPiwLl26pNjYWEVFRbmlxvHjxx1P\nDwOAvDDzCQAucOnSJUmXH9l6K7rV+wPw90H4BOBWV5+jGRcXp969e2v9+vXq3LmzatSooWbNmmnq\n1Kmy2+053rt582ZFR0erVq1aatmypVasWHHNGgcPHtTTTz+tevXqqWbNmoqOjtaGDRsc6/ft26fq\n1asrKipKf3yo2zvvvKOwsDAtXLjwuvuwf/9+PfXUU6pXr57Cw8PVrVs3JSYm5tinkSNHSpJ69uyZ\n5/mbU6dOzbHd1TOku3btUlxcnMLDw9WoUSPFx8crIyMjxza//PKLnnvuOTVs2FA1atRQx44d9ckn\nn1y3/xEjRqhnz56SpJEjRyosLEzHjx93arwtW7aoT58+uu+++1StWjU1adJEo0ePdjyP+oMPPshV\n48o+/7HeHz+LP74+depU1ahRQ19++aUaNWqk2rVra8mSJZKk3377TePHj1eTJk1UvXp1tWnTRnPm\nzBEP6APyJ9+xY8eO9XQTALzXhx9+qHPnzunRRx91LB86dEjLly9X69at9fDDDyslJUUffvihSpYs\nqfDwcEmXg2ffvn1VqFAh9e7dW2XLltXrr7+ukydPqmDBgo7x9u/fr+7du+vixYvq2bOnGjVqpH37\n9mnmzJmqVKmSqlSpolKlSik7O1uffPKJgoODVb16df33v//V0KFD1ahRo+uek7pz507FxsYqNTVV\ncXFxioiI0J49ezRnzhyVKFFC4eHhuv3221WwYEHt3r1b/fv3V7du3XTPPffkGuu2226TZVmO7bp0\n6aJKlSopMTFR+/bt02effab7779fnTp10oULF/TRRx8pPT1dTZs2lSSlpKSoa9euOnbsmGJjY9Wi\nRQv9/PPPmjlzpgIDA1WnTp1r7kPJkiVVqlQpbdu2TVFRUXr00UdVvXp1nTlz5qbG27hxo/r06aPg\n4GD16NFDTZs2VWZmppYvX67Tp0+rZcuWCgoKUqFChXLUuOeee7R161Zt3bpVjz76qIoWLero6erX\nt27dqm+++UabNm3S448/rpo1ayoiIkIFChRQTEyMtm3bpm7duqlNmza6cOGCZs+erTNnzqhZs2bO\n/6EE4FkWALhRjx49rAcffDDHcmhoqLV69WrHaxcvXrTq169vRUVFOV7r1KmTFRERYZ07d87x2pYt\nW6zQ0NBc47Vs2dJKT093vHbp0iUrJibGeuCBB6yMjAzLsiwrMzPTat++vVW/fn3r5MmTVufOna0G\nDRpYKSkp1+2/a9euVq1atayff/45R7+dOnWywsPDrdOnT1uWZVnLli2zQkNDra+//vq6411ru+HD\nh1uhoaHWrFmzHK9lZ2dbkZGRVkRERI7trtXzkCFDrOrVq1unTp3Ks+7XX39thYaGWsuWLXN6vN69\ne1sPPvig47O8olu3blbt2rWvW+PNN9+0QkNDrWPHjuV479WvX1l+8803c21XrVo1a9++fTlef+21\n16zQ0FBr7969ee4zgFsTh90BGBcYGJhjxqpAgQIKCQnRqVOnJEmnT5/W7t271bZtWwUFBTm2a9iw\nYY5D2qmpqdq6dasiIiJ08eJFnTlzRmfOnNHvv/+uyMhInTp1Srt27ZIk+fv766WXXlJ6erqio6OV\nnJysMWPGqHTp0nn2eerUKe3YsUMdOnTQHXfckaPf3r176+LFi9q8ebOrPha1bdvW8bOPj4/uvfde\nx2dit9uVmJioevXqyc/Pz7GvZ86cUatWrZSZmenUVebOjDd9+nQtW7ZMAQEBjvenpqYqKChI58+f\nd9HeX9a4ceMcy1988YVCQ0MVHByco8eWLVtKktauXevS+gDcj6vdARhXrFgx+fjk/H/fgIAAxzmf\nJ06ckCSVL18+13srVaqknTt3SpKOHTsmSUpISFBCQsI1a/3888+On6tVq6a4uDjNmjVLTZs21T/+\n8Y/r9nmlj5CQkFzrKleuLEn66aefrjuGM0qWLJljuWDBgo4LhVJTU3Xu3DklJibmON/0j/64rzfi\nzHi+vr46duyYpkyZooMHD+ro0aNuu5fn1Z/B0aNHdfHiRd1///3X7RFA/kH4BGDc1cHzajabTZJy\nXWwjKcdFSdnZ2ZKk2NhYx0zY1e6+++4c7/3+++8lSUlJSUpJSdHtt9+eZx/WdS5oudKHv79/nts4\n63qfy5V9bd26taKjo6+5Tbly5W66ljPjLVy4UGPGjFFISIjq1aunVq1aqWbNmkpISNDy5ctvuua1\n6l/t6s8gOztbdevW1YABA665/fVmrgHcmgifAG45ZcqUkc1mu+Y9I/941XSZMmUkXZ6Ze+CBB3Js\nd/DgQR0/flyBgYGO1+bMmaOkpCQNGTJE06ZN05gxY/TOO+9ctw9J+uGHH3KtO3z4sCTlOBzvTiVK\nlFBgYKCysrJy7etPP/2kPXv+v727B0lvj8MA/lwKh4pSoYaiFxOhIYiGkCIcIoqGhigsEakhMsre\nKIheQAohFwdPRUOQQ4NoZHQgiBZ1yoSKKG9Cc9AQRJC9mOgd/uTFf/eWcUO68Hw2z8v3fI8OPp7z\nOz//TDnX76r38vICq9UKtVqNjY0NZGf//bVht9s/Pc5bmIxGoynL34YTfKakpASRSORdj/f39zg8\nPER5eXladYjo5+CYTyL6ceRyOerq6iCKYkpIOT09RSgUSr4uKipCdXU1dnZ2Um4Dv76+YnZ2FqOj\no4jFYgB+3b612+1obGyE0WjE4OAgvF7vh1fu3p6MF0URNzc3yeXRaBQOhwMSieTLk+i/hbHfp5X6\nTHZ2NjQaDfx+P8LhcMo6q9WK4eFh3N3dfXu95+dnPD09oaKiIiV4Xl5eIhgMAkDyPc7Kynp3boWF\nhQCQcoyHhwf4/f60+mxqakI4HIbP50tZvra2hrGxsYz/UxQR/Xe88klEP9L09DT0ej20Wi30en1y\neh2ZTJay3fz8PHp7e9HZ2QmdTgepVIq9vT2cnZ1hcnISMpkMiUQCc3NziMfjMJvNAID+/n6IogiL\nxYKGhoZ3Yw1/r9/V1QWdTofc3FyIoohQKIT5+fmU6YPSIZfLAQBOpxO3t7dob29Pe9+pqSkcHR1B\nr9dDr9ejuLgYPp8PXq8X3d3dUKlUX+ol3Xo1NTXweDzIy8uDQqHA1dUVtra2kkE6EomgoKAg+dmI\noohEIoGOjg40NzfDYrFgcXER19fXkEgkcLvdyMnJSatHo9GIg4MDmEwm9PT0QKVS4fj4GLu7u9Bo\nNMlpqIjo/4Phk4h+pOrqamxubsJms2FlZQX5+fkwmUy4uLjAyclJcrva2lo4nU4sLy/D4XAgFotB\noVDAarWio6MDwK8xi8FgEOPj48mHmCQSCcxmM/r6+rCwsABBEP6xj7f6giBgY2MD8XgcVVVVWF1d\n/ddxph+pr69HW1sbvF4vAoEAWlpa0t63rKwMbrcbgiDA7Xbj8fERpaWlmJmZgcFg+HIv6daz2+1Y\nWlrC9vY2otEoSkpKMDAwAKVSiZGREQQCAbS2tkKpVMJgMMDj8eD8/BxqtRplZWVYX1+HzWaDIAiQ\nyWTQarWorKzExMTEpz1KpVK4XC4IgoD9/X24XC4UFxdjaGgIAwMDn44fJqKf54/ERyPqiYiIiIi+\nEX8yEhEREVHGMHwSERERUcYwfBIRERFRxjB8EhEREVHGMHwSERERUcYwfBIRERFRxjB8EhEREVHG\nMHwSERERUcYwfBIRERFRxjB8EhEREVHG/AUKMuiNLpQVeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14c90acc400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor_11    0.491205\n",
      "Sensor_9     0.134102\n",
      "Sensor_4     0.093463\n",
      "Sensor_12    0.042893\n",
      "Sensor_14    0.034412\n",
      "Sensor_7     0.034160\n",
      "Sensor_15    0.029577\n",
      "Sensor_21    0.027591\n",
      "Sensor_3     0.024412\n",
      "Sensor_2     0.023597\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "importances = single_rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feature_names = X.columns    \n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "plt.title(\"Feature ranking\", fontsize = 20)\n",
    "plt.bar(range(X.shape[1]), importances[indices], color=\"b\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices) #feature_names, rotation='vertical')\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.ylabel(\"importance\", fontsize = 18)\n",
    "plt.xlabel(\"index of the feature\", fontsize = 18)\n",
    "plt.show()\n",
    "# list feature importance\n",
    "important_features = pd.Series(data=single_rf.feature_importances_,index=X.columns)\n",
    "important_features.sort_values(ascending=False,inplace=True)\n",
    "print(important_features.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 22)\n",
      "(20631, 16)\n"
     ]
    }
   ],
   "source": [
    "#把不重要的几个feature drop了\n",
    "print(train_no_leakage.shape)\n",
    "vars_to_drop = [\"Sensor_\"+str(i) for i in [5, 15, 9, 17, 4, 18]]\n",
    "train_final = train_no_leakage.drop(vars_to_drop, axis = 1)\n",
    "print(train_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Sensor_1\n",
      "Sensor_2\n",
      "Sensor_3\n",
      "Sensor_6\n",
      "Sensor_7\n",
      "Sensor_8\n",
      "Sensor_10\n",
      "Sensor_11\n",
      "Sensor_12\n",
      "Sensor_13\n",
      "Sensor_14\n",
      "Sensor_16\n",
      "Sensor_19\n",
      "Sensor_20\n",
      "Sensor_21\n",
      "Target_Remaining_Useful_Life\n"
     ]
    }
   ],
   "source": [
    "# identify categorical and numeric fields\n",
    "# 不知道这有什么用\n",
    "from sklearn import preprocessing\n",
    "categorical = train_final.select_dtypes(include=['object'])\n",
    "numeric = train_final.select_dtypes(exclude=['object'])\n",
    "print(categorical.columns.values)\n",
    "# create dummy variables (if any categorical fields)\n",
    "for name, values in categorical.items():\n",
    "    print(name)\n",
    "    dummies = pd.get_dummies(values.str.strip(), prefix = name, dummy_na=True)\n",
    "    numeric = pd.concat([numeric, dummies], axis=1)\n",
    "# imputation (if any NULL values)\n",
    "for name in numeric:\n",
    "    print(name)\n",
    "    if pd.isnull(numeric[name]).sum() > 0:\n",
    "        numeric[\"%s_mi\" % (name)] = pd.isnull(numeric[name])\n",
    "        median = numeric[name].median()\n",
    "        numeric[name] = numeric[name].apply(lambda x: median if pd.isnull(x) else x)\n",
    "y = numeric['Target_Remaining_Useful_Life']\n",
    "X = numeric.drop(['Target_Remaining_Useful_Life'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16504, 15)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   16.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('standardize', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=9,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=25, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False))])\n",
      "Random Forest Mean Squared Error:  1799.5276243279602\n",
      "Random Forest Mean Absolute Error:  30.25600504941975\n",
      "Random Forest r-squared:  0.6192426376800281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cv': KFold(n_splits=5, random_state=None, shuffle=False),\n",
       " 'error_score': 'raise',\n",
       " 'estimator': Pipeline(memory=None,\n",
       "      steps=[('standardize', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "            max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False))]),\n",
       " 'estimator__memory': None,\n",
       " 'estimator__model': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "            max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " 'estimator__model__bootstrap': True,\n",
       " 'estimator__model__criterion': 'mse',\n",
       " 'estimator__model__max_depth': None,\n",
       " 'estimator__model__max_features': 'auto',\n",
       " 'estimator__model__max_leaf_nodes': None,\n",
       " 'estimator__model__min_impurity_decrease': 0.0,\n",
       " 'estimator__model__min_impurity_split': None,\n",
       " 'estimator__model__min_samples_leaf': 1,\n",
       " 'estimator__model__min_samples_split': 2,\n",
       " 'estimator__model__min_weight_fraction_leaf': 0.0,\n",
       " 'estimator__model__n_estimators': 10,\n",
       " 'estimator__model__n_jobs': 1,\n",
       " 'estimator__model__oob_score': False,\n",
       " 'estimator__model__random_state': None,\n",
       " 'estimator__model__verbose': 0,\n",
       " 'estimator__model__warm_start': False,\n",
       " 'estimator__standardize': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'estimator__standardize__copy': True,\n",
       " 'estimator__standardize__with_mean': True,\n",
       " 'estimator__standardize__with_std': True,\n",
       " 'estimator__steps': [('standardize',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('model',\n",
       "   RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "              max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0, warm_start=False))],\n",
       " 'fit_params': None,\n",
       " 'iid': True,\n",
       " 'n_jobs': -1,\n",
       " 'param_grid': {'model__max_depth': [7, 8, 9, 10, 11, 12],\n",
       "  'model__min_samples_leaf': [2, 10, 25, 50, 100]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': True,\n",
       " 'scoring': 'neg_mean_squared_error',\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "# choose the model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = ensemble.RandomForestRegressor()\n",
    "# set up 5-fold cross-validation\n",
    "from sklearn import model_selection\n",
    "cv = model_selection.KFold(5)\n",
    "# pipeline standardization and model\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps=[('standardize', preprocessing.StandardScaler())\n",
    "                           , ('model', rf) ])\n",
    "# tune the model\n",
    "my_min_samples_leaf = [2, 10, 25, 50, 100]\n",
    "my_max_depth = [7, 8, 9, 10, 11, 12]\n",
    "# run the model using gridsearch, select the model with best search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "optimized_rf = GridSearchCV(estimator=pipeline\n",
    "                            , cv=cv\n",
    "                            , param_grid =dict(model__min_samples_leaf = my_min_samples_leaf, model__max_depth = my_max_depth)\n",
    "                            , scoring = 'neg_mean_squared_error'\n",
    "                            , verbose = 1\n",
    "                            , n_jobs = -1\n",
    "                           )\n",
    "optimized_rf.fit(X_train, y_train)\n",
    "# show the best model estimators\n",
    "print(optimized_rf.best_estimator_)\n",
    "# evaluate metrics on holdout\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "y_pred = optimized_rf.predict(X_test)\n",
    "print(\"Random Forest Mean Squared Error: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"Random Forest Mean Absolute Error: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"Random Forest r-squared: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardize', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=9,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=25, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 拿全部的feature测一下\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "# choose the model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = ensemble.RandomForestRegressor()\n",
    "# set up 5-fold cross-validation\n",
    "from sklearn import model_selection\n",
    "cv = model_selection.KFold(5)\n",
    "# pipeline standardization and model\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps=[('standardize', preprocessing.StandardScaler())\n",
    "                           , ('model', rf) ])\n",
    "# tune the model\n",
    "my_min_samples_leaf = [2, 10, 25, 50, 100]\n",
    "my_max_depth = [7, 8, 9, 10, 11, 12]\n",
    "# run the model using gridsearch, select the model with best search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "optimized_rf = GridSearchCV(estimator=pipeline\n",
    "                            , cv=cv\n",
    "                            , param_grid =dict(model__min_samples_leaf = my_min_samples_leaf, model__max_depth = my_max_depth)\n",
    "                            , scoring = 'neg_mean_squared_error'\n",
    "                            , verbose = 1\n",
    "                            , n_jobs = -1\n",
    "                           )\n",
    "optimized_rf.fit(X_train, y_train)\n",
    "# show the best model estimators\n",
    "print(optimized_rf.best_estimator_)\n",
    "# evaluate metrics on holdout\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "y_pred = optimized_rf.predict(X_test)\n",
    "print(\"Random Forest Mean Squared Error: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"Random Forest Mean Absolute Error: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"Random Forest r-squared: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Mean Squared Error:  1801.5603140772732\n",
      "Random Forest Mean Absolute Error:  30.270853383794073\n",
      "Random Forest r-squared:  0.6188125461510623\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=9,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=25, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
    "rf.fit(X_train, y_train)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Random Forest Mean Squared Error: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"Random Forest Mean Absolute Error: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"Random Forest r-squared: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor_1</th>\n",
       "      <th>Sensor_2</th>\n",
       "      <th>Sensor_3</th>\n",
       "      <th>Sensor_6</th>\n",
       "      <th>Sensor_7</th>\n",
       "      <th>Sensor_8</th>\n",
       "      <th>Sensor_10</th>\n",
       "      <th>Sensor_11</th>\n",
       "      <th>Sensor_12</th>\n",
       "      <th>Sensor_13</th>\n",
       "      <th>Sensor_14</th>\n",
       "      <th>Sensor_16</th>\n",
       "      <th>Sensor_19</th>\n",
       "      <th>Sensor_20</th>\n",
       "      <th>Sensor_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6240</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.73</td>\n",
       "      <td>1587.11</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.76</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.47</td>\n",
       "      <td>521.29</td>\n",
       "      <td>2388.17</td>\n",
       "      <td>8135.19</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.92</td>\n",
       "      <td>23.2388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.45</td>\n",
       "      <td>1591.03</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.76</td>\n",
       "      <td>2388.10</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.51</td>\n",
       "      <td>520.71</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8140.24</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.78</td>\n",
       "      <td>23.2820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.89</td>\n",
       "      <td>1595.01</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.79</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.45</td>\n",
       "      <td>521.28</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8207.79</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.79</td>\n",
       "      <td>23.2424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.67</td>\n",
       "      <td>1598.60</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.62</td>\n",
       "      <td>2388.18</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.72</td>\n",
       "      <td>520.39</td>\n",
       "      <td>2388.19</td>\n",
       "      <td>8119.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.77</td>\n",
       "      <td>23.2369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.88</td>\n",
       "      <td>1594.96</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.03</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.59</td>\n",
       "      <td>520.66</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8160.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.84</td>\n",
       "      <td>23.3358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.53</td>\n",
       "      <td>1582.19</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.32</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.25</td>\n",
       "      <td>522.47</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8145.19</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6091</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.24</td>\n",
       "      <td>1588.38</td>\n",
       "      <td>21.60</td>\n",
       "      <td>553.83</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.14</td>\n",
       "      <td>521.85</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8143.61</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.2901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19955</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.80</td>\n",
       "      <td>1586.30</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.53</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.26</td>\n",
       "      <td>521.63</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>8132.53</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.23</td>\n",
       "      <td>1588.43</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.26</td>\n",
       "      <td>2388.10</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.58</td>\n",
       "      <td>521.82</td>\n",
       "      <td>2388.10</td>\n",
       "      <td>8137.55</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.92</td>\n",
       "      <td>23.3163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>518.67</td>\n",
       "      <td>643.29</td>\n",
       "      <td>1589.52</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.14</td>\n",
       "      <td>2388.24</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.81</td>\n",
       "      <td>521.11</td>\n",
       "      <td>2388.20</td>\n",
       "      <td>8124.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.75</td>\n",
       "      <td>23.2851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11324</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.53</td>\n",
       "      <td>1593.73</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.62</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.40</td>\n",
       "      <td>521.76</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8127.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.59</td>\n",
       "      <td>1586.41</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.54</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.61</td>\n",
       "      <td>521.51</td>\n",
       "      <td>2388.13</td>\n",
       "      <td>8135.78</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.93</td>\n",
       "      <td>23.3577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13088</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.90</td>\n",
       "      <td>1596.66</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.54</td>\n",
       "      <td>2388.15</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.94</td>\n",
       "      <td>520.47</td>\n",
       "      <td>2388.18</td>\n",
       "      <td>8141.16</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.54</td>\n",
       "      <td>23.1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.61</td>\n",
       "      <td>1592.49</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.11</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.64</td>\n",
       "      <td>521.22</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8169.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.81</td>\n",
       "      <td>23.2581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.54</td>\n",
       "      <td>1583.29</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.55</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.44</td>\n",
       "      <td>521.24</td>\n",
       "      <td>2388.12</td>\n",
       "      <td>8136.22</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.75</td>\n",
       "      <td>23.4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13449</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.78</td>\n",
       "      <td>1584.94</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.23</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.39</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8140.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.04</td>\n",
       "      <td>23.3550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9070</th>\n",
       "      <td>518.67</td>\n",
       "      <td>641.98</td>\n",
       "      <td>1579.78</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.98</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.27</td>\n",
       "      <td>522.38</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8140.33</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.07</td>\n",
       "      <td>23.3601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12188</th>\n",
       "      <td>518.67</td>\n",
       "      <td>641.87</td>\n",
       "      <td>1592.34</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.88</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.67</td>\n",
       "      <td>520.87</td>\n",
       "      <td>2388.13</td>\n",
       "      <td>8132.97</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.84</td>\n",
       "      <td>23.2188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>518.67</td>\n",
       "      <td>643.18</td>\n",
       "      <td>1584.45</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.83</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.66</td>\n",
       "      <td>521.43</td>\n",
       "      <td>2388.17</td>\n",
       "      <td>8126.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.92</td>\n",
       "      <td>23.3256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9369</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.30</td>\n",
       "      <td>1587.08</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.55</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.29</td>\n",
       "      <td>522.44</td>\n",
       "      <td>2387.99</td>\n",
       "      <td>8154.72</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.94</td>\n",
       "      <td>23.3078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>518.67</td>\n",
       "      <td>641.83</td>\n",
       "      <td>1581.59</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.51</td>\n",
       "      <td>2387.97</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.34</td>\n",
       "      <td>522.02</td>\n",
       "      <td>2387.99</td>\n",
       "      <td>8145.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.10</td>\n",
       "      <td>23.5199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9707</th>\n",
       "      <td>518.67</td>\n",
       "      <td>643.34</td>\n",
       "      <td>1598.92</td>\n",
       "      <td>21.61</td>\n",
       "      <td>551.34</td>\n",
       "      <td>2388.22</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.03</td>\n",
       "      <td>519.88</td>\n",
       "      <td>2388.29</td>\n",
       "      <td>8134.67</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.50</td>\n",
       "      <td>23.1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9803</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.43</td>\n",
       "      <td>1584.14</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.86</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.36</td>\n",
       "      <td>521.06</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8147.19</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.77</td>\n",
       "      <td>23.2351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20522</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.86</td>\n",
       "      <td>1587.74</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.48</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.47</td>\n",
       "      <td>521.67</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>8141.18</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.3381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>518.67</td>\n",
       "      <td>641.93</td>\n",
       "      <td>1578.34</td>\n",
       "      <td>21.60</td>\n",
       "      <td>553.74</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.25</td>\n",
       "      <td>521.88</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>8139.69</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.93</td>\n",
       "      <td>1595.20</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.86</td>\n",
       "      <td>2388.12</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.60</td>\n",
       "      <td>520.97</td>\n",
       "      <td>2388.15</td>\n",
       "      <td>8133.37</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.74</td>\n",
       "      <td>23.2711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17382</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.74</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.81</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.51</td>\n",
       "      <td>521.70</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8143.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.54</td>\n",
       "      <td>23.2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.58</td>\n",
       "      <td>1586.67</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.00</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.50</td>\n",
       "      <td>520.77</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8140.96</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.89</td>\n",
       "      <td>23.2364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18144</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.94</td>\n",
       "      <td>1593.53</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.40</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.54</td>\n",
       "      <td>521.26</td>\n",
       "      <td>2388.13</td>\n",
       "      <td>8137.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.92</td>\n",
       "      <td>23.2576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16117</th>\n",
       "      <td>518.67</td>\n",
       "      <td>643.65</td>\n",
       "      <td>1602.53</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.42</td>\n",
       "      <td>2388.10</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.85</td>\n",
       "      <td>520.48</td>\n",
       "      <td>2388.15</td>\n",
       "      <td>8188.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.56</td>\n",
       "      <td>23.2028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17683</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.67</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.72</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.64</td>\n",
       "      <td>521.52</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8139.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.94</td>\n",
       "      <td>23.2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17666</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.66</td>\n",
       "      <td>1589.24</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.46</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.49</td>\n",
       "      <td>521.82</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8138.49</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.79</td>\n",
       "      <td>23.2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16387</th>\n",
       "      <td>518.67</td>\n",
       "      <td>641.57</td>\n",
       "      <td>1580.98</td>\n",
       "      <td>21.60</td>\n",
       "      <td>554.80</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.10</td>\n",
       "      <td>522.84</td>\n",
       "      <td>2387.94</td>\n",
       "      <td>8146.73</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.05</td>\n",
       "      <td>23.6184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10576</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.40</td>\n",
       "      <td>1579.86</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.66</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.14</td>\n",
       "      <td>522.48</td>\n",
       "      <td>2387.92</td>\n",
       "      <td>8139.95</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12107</th>\n",
       "      <td>518.67</td>\n",
       "      <td>643.19</td>\n",
       "      <td>1588.26</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.32</td>\n",
       "      <td>2388.18</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.87</td>\n",
       "      <td>520.72</td>\n",
       "      <td>2388.23</td>\n",
       "      <td>8123.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.50</td>\n",
       "      <td>23.1544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6784</th>\n",
       "      <td>518.67</td>\n",
       "      <td>643.58</td>\n",
       "      <td>1602.55</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.66</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.83</td>\n",
       "      <td>521.15</td>\n",
       "      <td>2388.12</td>\n",
       "      <td>8187.58</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.58</td>\n",
       "      <td>23.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10983</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.52</td>\n",
       "      <td>1587.64</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.52</td>\n",
       "      <td>2388.13</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.48</td>\n",
       "      <td>521.70</td>\n",
       "      <td>2388.12</td>\n",
       "      <td>8136.86</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.89</td>\n",
       "      <td>23.2844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13507</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.38</td>\n",
       "      <td>1587.56</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.69</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.52</td>\n",
       "      <td>521.20</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>8139.75</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.97</td>\n",
       "      <td>23.2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17914</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.01</td>\n",
       "      <td>1587.31</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.04</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.51</td>\n",
       "      <td>522.55</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>8150.45</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.84</td>\n",
       "      <td>23.2404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12198</th>\n",
       "      <td>518.67</td>\n",
       "      <td>643.05</td>\n",
       "      <td>1592.31</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.58</td>\n",
       "      <td>2388.17</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.67</td>\n",
       "      <td>521.20</td>\n",
       "      <td>2388.16</td>\n",
       "      <td>8129.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.62</td>\n",
       "      <td>23.2661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14629</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.53</td>\n",
       "      <td>1593.64</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.76</td>\n",
       "      <td>2388.14</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.54</td>\n",
       "      <td>521.62</td>\n",
       "      <td>2388.12</td>\n",
       "      <td>8120.49</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.79</td>\n",
       "      <td>23.1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.76</td>\n",
       "      <td>1589.66</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.81</td>\n",
       "      <td>2388.19</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.72</td>\n",
       "      <td>520.89</td>\n",
       "      <td>2388.14</td>\n",
       "      <td>8124.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5682</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.69</td>\n",
       "      <td>1593.00</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.37</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.52</td>\n",
       "      <td>521.73</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8141.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.89</td>\n",
       "      <td>23.3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.05</td>\n",
       "      <td>1584.36</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.94</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.46</td>\n",
       "      <td>521.47</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>8161.21</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.3126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>518.67</td>\n",
       "      <td>643.25</td>\n",
       "      <td>1599.99</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.27</td>\n",
       "      <td>2388.13</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.43</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.10</td>\n",
       "      <td>8135.84</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.83</td>\n",
       "      <td>23.2979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16630</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.58</td>\n",
       "      <td>21.61</td>\n",
       "      <td>555.03</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.08</td>\n",
       "      <td>522.60</td>\n",
       "      <td>2387.98</td>\n",
       "      <td>8138.96</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.98</td>\n",
       "      <td>23.3607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18815</th>\n",
       "      <td>518.67</td>\n",
       "      <td>643.15</td>\n",
       "      <td>1595.44</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.09</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.84</td>\n",
       "      <td>520.53</td>\n",
       "      <td>2388.10</td>\n",
       "      <td>8177.59</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.79</td>\n",
       "      <td>23.2632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9161</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.82</td>\n",
       "      <td>1585.75</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.24</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.43</td>\n",
       "      <td>522.14</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8151.92</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.2310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7644</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1589.19</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.50</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.38</td>\n",
       "      <td>520.96</td>\n",
       "      <td>2388.12</td>\n",
       "      <td>8139.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.71</td>\n",
       "      <td>23.2662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14192</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.25</td>\n",
       "      <td>1585.34</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.93</td>\n",
       "      <td>2388.13</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.68</td>\n",
       "      <td>521.34</td>\n",
       "      <td>2388.10</td>\n",
       "      <td>8131.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.89</td>\n",
       "      <td>23.2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13686</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.20</td>\n",
       "      <td>1581.45</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.56</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.34</td>\n",
       "      <td>522.03</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8145.83</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7962</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.32</td>\n",
       "      <td>1590.52</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.71</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.44</td>\n",
       "      <td>522.26</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8155.64</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.86</td>\n",
       "      <td>23.3819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8060</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1589.20</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.13</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.37</td>\n",
       "      <td>522.34</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>8141.16</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.97</td>\n",
       "      <td>23.2955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.92</td>\n",
       "      <td>1580.98</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.06</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.36</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>8147.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.03</td>\n",
       "      <td>23.3007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.87</td>\n",
       "      <td>1588.19</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.11</td>\n",
       "      <td>2388.15</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.45</td>\n",
       "      <td>521.50</td>\n",
       "      <td>2388.17</td>\n",
       "      <td>8119.46</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.91</td>\n",
       "      <td>23.3140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8222</th>\n",
       "      <td>518.67</td>\n",
       "      <td>643.70</td>\n",
       "      <td>1597.51</td>\n",
       "      <td>21.61</td>\n",
       "      <td>551.64</td>\n",
       "      <td>2388.27</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.00</td>\n",
       "      <td>519.61</td>\n",
       "      <td>2388.15</td>\n",
       "      <td>8142.79</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.51</td>\n",
       "      <td>23.1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9449</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.53</td>\n",
       "      <td>1598.55</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.46</td>\n",
       "      <td>2387.99</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.36</td>\n",
       "      <td>521.07</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8189.63</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.77</td>\n",
       "      <td>23.2795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8471</th>\n",
       "      <td>518.67</td>\n",
       "      <td>641.95</td>\n",
       "      <td>1588.72</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.18</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.28</td>\n",
       "      <td>522.37</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8145.59</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.07</td>\n",
       "      <td>23.3382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17048</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.29</td>\n",
       "      <td>1591.76</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.83</td>\n",
       "      <td>2388.14</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.85</td>\n",
       "      <td>521.03</td>\n",
       "      <td>2388.16</td>\n",
       "      <td>8135.68</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.66</td>\n",
       "      <td>23.3142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.29</td>\n",
       "      <td>1582.42</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.02</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.24</td>\n",
       "      <td>521.89</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>8146.48</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.07</td>\n",
       "      <td>23.3772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16504 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sensor_1  Sensor_2  Sensor_3  Sensor_6  Sensor_7  Sensor_8  Sensor_10  \\\n",
       "6240     518.67    642.73   1587.11     21.61    553.76   2388.07        1.3   \n",
       "3161     518.67    642.45   1591.03     21.61    552.76   2388.10        1.3   \n",
       "1887     518.67    642.89   1595.01     21.61    552.79   2388.02        1.3   \n",
       "151      518.67    642.67   1598.60     21.61    552.62   2388.18        1.3   \n",
       "8768     518.67    642.88   1594.96     21.61    553.03   2388.07        1.3   \n",
       "5906     518.67    642.53   1582.19     21.61    554.32   2388.05        1.3   \n",
       "6091     518.67    642.24   1588.38     21.60    553.83   2388.03        1.3   \n",
       "19955    518.67    642.80   1586.30     21.61    554.53   2388.02        1.3   \n",
       "2586     518.67    642.23   1588.43     21.61    553.26   2388.10        1.3   \n",
       "3066     518.67    643.29   1589.52     21.61    553.14   2388.24        1.3   \n",
       "11324    518.67    642.53   1593.73     21.61    553.62   2388.08        1.3   \n",
       "3980     518.67    642.59   1586.41     21.61    553.54   2388.09        1.3   \n",
       "13088    518.67    642.90   1596.66     21.61    552.54   2388.15        1.3   \n",
       "1059     518.67    642.61   1592.49     21.61    553.11   2388.01        1.3   \n",
       "13999    518.67    642.54   1583.29     21.61    553.55   2388.07        1.3   \n",
       "13449    518.67    642.78   1584.94     21.61    554.23   2388.03        1.3   \n",
       "9070     518.67    641.98   1579.78     21.61    554.98   2388.03        1.3   \n",
       "12188    518.67    641.87   1592.34     21.61    552.88   2388.05        1.3   \n",
       "4370     518.67    643.18   1584.45     21.61    553.83   2388.11        1.3   \n",
       "9369     518.67    642.30   1587.08     21.61    554.55   2388.00        1.3   \n",
       "9115     518.67    641.83   1581.59     21.61    553.51   2387.97        1.3   \n",
       "9707     518.67    643.34   1598.92     21.61    551.34   2388.22        1.3   \n",
       "9803     518.67    642.43   1584.14     21.61    553.86   2388.05        1.3   \n",
       "20522    518.67    642.86   1587.74     21.61    553.48   2388.08        1.3   \n",
       "6050     518.67    641.93   1578.34     21.60    553.74   2388.01        1.3   \n",
       "6171     518.67    642.93   1595.20     21.61    552.86   2388.12        1.3   \n",
       "17382    518.67    642.74   1587.99     21.61    553.81   2388.05        1.3   \n",
       "4053     518.67    642.58   1586.67     21.61    553.00   2388.11        1.3   \n",
       "18144    518.67    642.94   1593.53     21.61    553.40   2388.07        1.3   \n",
       "16117    518.67    643.65   1602.53     21.61    552.42   2388.10        1.3   \n",
       "...         ...       ...       ...       ...       ...       ...        ...   \n",
       "17683    518.67    642.67   1591.82     21.61    553.72   2388.08        1.3   \n",
       "17666    518.67    642.66   1589.24     21.61    553.46   2388.06        1.3   \n",
       "16387    518.67    641.57   1580.98     21.60    554.80   2388.00        1.3   \n",
       "10576    518.67    642.40   1579.86     21.61    554.66   2388.00        1.3   \n",
       "12107    518.67    643.19   1588.26     21.61    552.32   2388.18        1.3   \n",
       "6784     518.67    643.58   1602.55     21.61    552.66   2388.08        1.3   \n",
       "10983    518.67    642.52   1587.64     21.61    553.52   2388.13        1.3   \n",
       "13507    518.67    642.38   1587.56     21.61    552.69   2388.09        1.3   \n",
       "17914    518.67    642.01   1587.31     21.61    554.04   2388.09        1.3   \n",
       "12198    518.67    643.05   1592.31     21.61    552.58   2388.17        1.3   \n",
       "14629    518.67    642.53   1593.64     21.61    552.76   2388.14        1.3   \n",
       "3824     518.67    642.76   1589.66     21.61    552.81   2388.19        1.3   \n",
       "5682     518.67    642.69   1593.00     21.61    553.37   2388.06        1.3   \n",
       "3503     518.67    642.05   1584.36     21.61    553.94   2388.01        1.3   \n",
       "2558     518.67    643.25   1599.99     21.61    553.27   2388.13        1.3   \n",
       "16630    518.67    642.37   1582.58     21.61    555.03   2388.00        1.3   \n",
       "18815    518.67    643.15   1595.44     21.61    552.09   2388.09        1.3   \n",
       "9161     518.67    642.82   1585.75     21.61    554.24   2388.01        1.3   \n",
       "7644     518.67    642.46   1589.19     21.61    553.50   2388.11        1.3   \n",
       "14192    518.67    642.25   1585.34     21.61    553.93   2388.13        1.3   \n",
       "13686    518.67    642.20   1581.45     21.61    553.56   2388.07        1.3   \n",
       "7962     518.67    642.32   1590.52     21.61    553.71   2388.05        1.3   \n",
       "8060     518.67    642.35   1589.20     21.61    554.13   2388.00        1.3   \n",
       "7916     518.67    642.92   1580.98     21.61    554.06   2388.04        1.3   \n",
       "1182     518.67    642.87   1588.19     21.61    553.11   2388.15        1.3   \n",
       "8222     518.67    643.70   1597.51     21.61    551.64   2388.27        1.3   \n",
       "9449     518.67    642.53   1598.55     21.61    553.46   2387.99        1.3   \n",
       "8471     518.67    641.95   1588.72     21.61    554.18   2388.00        1.3   \n",
       "17048    518.67    642.29   1591.76     21.61    552.83   2388.14        1.3   \n",
       "1318     518.67    642.29   1582.42     21.61    554.02   2388.08        1.3   \n",
       "\n",
       "       Sensor_11  Sensor_12  Sensor_13  Sensor_14  Sensor_16  Sensor_19  \\\n",
       "6240       47.47     521.29    2388.17    8135.19       0.03      100.0   \n",
       "3161       47.51     520.71    2388.08    8140.24       0.03      100.0   \n",
       "1887       47.45     521.28    2388.05    8207.79       0.03      100.0   \n",
       "151        47.72     520.39    2388.19    8119.00       0.03      100.0   \n",
       "8768       47.59     520.66    2388.06    8160.04       0.03      100.0   \n",
       "5906       47.25     522.47    2388.02    8145.19       0.03      100.0   \n",
       "6091       47.14     521.85    2388.04    8143.61       0.03      100.0   \n",
       "19955      47.26     521.63    2388.09    8132.53       0.03      100.0   \n",
       "2586       47.58     521.82    2388.10    8137.55       0.03      100.0   \n",
       "3066       47.81     521.11    2388.20    8124.81       0.03      100.0   \n",
       "11324      47.40     521.76    2388.08    8127.03       0.03      100.0   \n",
       "3980       47.61     521.51    2388.13    8135.78       0.03      100.0   \n",
       "13088      47.94     520.47    2388.18    8141.16       0.03      100.0   \n",
       "1059       47.64     521.22    2388.03    8169.99       0.03      100.0   \n",
       "13999      47.44     521.24    2388.12    8136.22       0.03      100.0   \n",
       "13449      47.39     521.66    2388.06    8140.30       0.03      100.0   \n",
       "9070       47.27     522.38    2388.03    8140.33       0.03      100.0   \n",
       "12188      47.67     520.87    2388.13    8132.97       0.03      100.0   \n",
       "4370       47.66     521.43    2388.17    8126.00       0.03      100.0   \n",
       "9369       47.29     522.44    2387.99    8154.72       0.03      100.0   \n",
       "9115       47.34     522.02    2387.99    8145.50       0.03      100.0   \n",
       "9707       48.03     519.88    2388.29    8134.67       0.03      100.0   \n",
       "9803       47.36     521.06    2388.05    8147.19       0.03      100.0   \n",
       "20522      47.47     521.67    2388.09    8141.18       0.03      100.0   \n",
       "6050       47.25     521.88    2388.11    8139.69       0.03      100.0   \n",
       "6171       47.60     520.97    2388.15    8133.37       0.03      100.0   \n",
       "17382      47.51     521.70    2388.05    8143.03       0.03      100.0   \n",
       "4053       47.50     520.77    2388.07    8140.96       0.03      100.0   \n",
       "18144      47.54     521.26    2388.13    8137.08       0.03      100.0   \n",
       "16117      47.85     520.48    2388.15    8188.14       0.03      100.0   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "17683      47.64     521.52    2388.05    8139.09       0.03      100.0   \n",
       "17666      47.49     521.82    2388.05    8138.49       0.03      100.0   \n",
       "16387      47.10     522.84    2387.94    8146.73       0.03      100.0   \n",
       "10576      47.14     522.48    2387.92    8139.95       0.03      100.0   \n",
       "12107      47.87     520.72    2388.23    8123.50       0.03      100.0   \n",
       "6784       47.83     521.15    2388.12    8187.58       0.03      100.0   \n",
       "10983      47.48     521.70    2388.12    8136.86       0.03      100.0   \n",
       "13507      47.52     521.20    2388.09    8139.75       0.03      100.0   \n",
       "17914      47.51     522.55    2388.01    8150.45       0.03      100.0   \n",
       "12198      47.67     521.20    2388.16    8129.17       0.03      100.0   \n",
       "14629      47.54     521.62    2388.12    8120.49       0.03      100.0   \n",
       "3824       47.72     520.89    2388.14    8124.99       0.03      100.0   \n",
       "5682       47.52     521.73    2388.08    8141.00       0.03      100.0   \n",
       "3503       47.46     521.47    2388.09    8161.21       0.03      100.0   \n",
       "2558       47.43     521.66    2388.10    8135.84       0.03      100.0   \n",
       "16630      47.08     522.60    2387.98    8138.96       0.03      100.0   \n",
       "18815      47.84     520.53    2388.10    8177.59       0.03      100.0   \n",
       "9161       47.43     522.14    2388.05    8151.92       0.03      100.0   \n",
       "7644       47.38     520.96    2388.12    8139.50       0.03      100.0   \n",
       "14192      47.68     521.34    2388.10    8131.08       0.03      100.0   \n",
       "13686      47.34     522.03    2388.07    8145.83       0.03      100.0   \n",
       "7962       47.44     522.26    2388.08    8155.64       0.03      100.0   \n",
       "8060       47.37     522.34    2388.00    8141.16       0.03      100.0   \n",
       "7916       47.36     522.28    2388.01    8147.50       0.03      100.0   \n",
       "1182       47.45     521.50    2388.17    8119.46       0.03      100.0   \n",
       "8222       48.00     519.61    2388.15    8142.79       0.03      100.0   \n",
       "9449       47.36     521.07    2388.02    8189.63       0.03      100.0   \n",
       "8471       47.28     522.37    2388.03    8145.59       0.03      100.0   \n",
       "17048      47.85     521.03    2388.16    8135.68       0.03      100.0   \n",
       "1318       47.24     521.89    2388.00    8146.48       0.03      100.0   \n",
       "\n",
       "       Sensor_20  Sensor_21  \n",
       "6240       38.92    23.2388  \n",
       "3161       38.78    23.2820  \n",
       "1887       38.79    23.2424  \n",
       "151        38.77    23.2369  \n",
       "8768       38.84    23.3358  \n",
       "5906       38.95    23.3742  \n",
       "6091       39.02    23.2901  \n",
       "19955      38.88    23.3220  \n",
       "2586       38.92    23.3163  \n",
       "3066       38.75    23.2851  \n",
       "11324      38.99    23.1992  \n",
       "3980       38.93    23.3577  \n",
       "13088      38.54    23.1045  \n",
       "1059       38.81    23.2581  \n",
       "13999      38.75    23.4152  \n",
       "13449      39.04    23.3550  \n",
       "9070       39.07    23.3601  \n",
       "12188      38.84    23.2188  \n",
       "4370       38.92    23.3256  \n",
       "9369       38.94    23.3078  \n",
       "9115       39.10    23.5199  \n",
       "9707       38.50    23.1368  \n",
       "9803       38.77    23.2351  \n",
       "20522      38.99    23.3381  \n",
       "6050       39.06    23.4081  \n",
       "6171       38.74    23.2711  \n",
       "17382      38.54    23.2264  \n",
       "4053       38.89    23.2364  \n",
       "18144      38.92    23.2576  \n",
       "16117      38.56    23.2028  \n",
       "...          ...        ...  \n",
       "17683      38.94    23.2875  \n",
       "17666      38.79    23.2133  \n",
       "16387      39.05    23.6184  \n",
       "10576      39.00    23.4603  \n",
       "12107      38.50    23.1544  \n",
       "6784       38.58    23.1000  \n",
       "10983      38.89    23.2844  \n",
       "13507      38.97    23.2125  \n",
       "17914      38.84    23.2404  \n",
       "12198      38.62    23.2661  \n",
       "14629      38.79    23.1894  \n",
       "3824       38.88    23.3476  \n",
       "5682       38.89    23.3445  \n",
       "3503       38.90    23.3126  \n",
       "2558       38.83    23.2979  \n",
       "16630      38.98    23.3607  \n",
       "18815      38.79    23.2632  \n",
       "9161       38.90    23.2310  \n",
       "7644       38.71    23.2662  \n",
       "14192      38.89    23.2812  \n",
       "13686      39.00    23.4773  \n",
       "7962       38.86    23.3819  \n",
       "8060       38.97    23.2955  \n",
       "7916       39.03    23.3007  \n",
       "1182       38.91    23.3140  \n",
       "8222       38.51    23.1990  \n",
       "9449       38.77    23.2795  \n",
       "8471       39.07    23.3382  \n",
       "17048      38.66    23.3142  \n",
       "1318       39.07    23.3772  \n",
       "\n",
       "[16504 rows x 15 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    191\n",
       "1    190\n",
       "2    189\n",
       "3    188\n",
       "4    187\n",
       "5    186\n",
       "6    185\n",
       "7    184\n",
       "8    183\n",
       "9    182\n",
       "Name: Target_Remaining_Useful_Life, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor_3</th>\n",
       "      <th>Sensor_6</th>\n",
       "      <th>Sensor_7</th>\n",
       "      <th>Sensor_8</th>\n",
       "      <th>Sensor_10</th>\n",
       "      <th>Sensor_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1589.70</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.36</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1591.82</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.75</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1587.99</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.26</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1582.79</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.45</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1582.85</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.00</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1584.47</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.67</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1592.32</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.34</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1582.96</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.85</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1590.98</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.69</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1591.24</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.59</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor_3  Sensor_6  Sensor_7  Sensor_8  Sensor_10  Sensor_11\n",
       "0   1589.70     21.61    554.36   2388.06        1.3      47.47\n",
       "1   1591.82     21.61    553.75   2388.04        1.3      47.49\n",
       "2   1587.99     21.61    554.26   2388.08        1.3      47.27\n",
       "3   1582.79     21.61    554.45   2388.11        1.3      47.13\n",
       "4   1582.85     21.61    554.00   2388.06        1.3      47.28\n",
       "5   1584.47     21.61    554.67   2388.02        1.3      47.16\n",
       "6   1592.32     21.61    554.34   2388.02        1.3      47.36\n",
       "7   1582.96     21.61    553.85   2388.00        1.3      47.24\n",
       "8   1590.98     21.61    553.69   2388.05        1.3      47.29\n",
       "9   1591.24     21.61    553.59   2388.05        1.3      47.03"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(max_train_size=None, n_splits=3)\n",
      "TRAIN: [0 1 2 3 4] TEST: [5 6]\n",
      "TRAIN: [0 1 2 3 4 5 6] TEST: [7 8]\n",
      "TRAIN: [0 1 2 3 4 5 6 7 8] TEST: [ 9 10]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "XX = X.iloc[0:11,2:8]\n",
    "yy = X.iloc[0:11,9:10]\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "print(tscv)  \n",
    "TimeSeriesSplit(max_train_size=None, n_splits=3)\n",
    "for train_index, test_index in tscv.split(XX):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = XX[train_index], XX[test_index]\n",
    "#     y_train, y_test = yy[train_index], yy[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
